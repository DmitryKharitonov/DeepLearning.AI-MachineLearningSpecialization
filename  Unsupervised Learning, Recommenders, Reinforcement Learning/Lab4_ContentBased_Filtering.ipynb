{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Given\n",
    "\n",
    "3 datasets:\n",
    "* $X_u$ for user's preferences/features\n",
    "* $X_m$ for items's features\n",
    "* $Y$ for each item rating\n",
    "\n",
    "# Find \n",
    "the content based filtering model, and predict movies to a new user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50884, 17), (50884, 17), (50884,))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# items\n",
    "\n",
    "x_m_data = np.load(\"./Lab4_data_items_orig.npz\")\n",
    "x_m = x_m_data['arr_0']\n",
    "m_features = x_m_data['arr_1']\n",
    "xm_start = 1 # exclude movie id\n",
    "xm_num_features = 16\n",
    "\n",
    "# users\n",
    "# there are really 300-ish users, but the qty of rows is boosted to match all other tables\n",
    "\n",
    "x_u = np.load(\"./Lab4_data_users_orig.npz\")['arr_0']\n",
    "xu_start = 3 # exclude user id, average rating and other not useful info\n",
    "xu_num_features = 14\n",
    "\n",
    "# targets\n",
    "\n",
    "targets = np.load(\"./Lab4_data_targets_orig.npz\")['arr_0']\n",
    "\n",
    "# check shapes\n",
    "\n",
    "x_m.shape, x_u.shape, targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50884, 17), (50884, 17), (50884, 1))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_scaler = StandardScaler()\n",
    "m_scaler.fit(x_m)\n",
    "x_m_scaled = m_scaler.transform(x_m)\n",
    "\n",
    "u_scaler = StandardScaler()\n",
    "u_scaler.fit(x_u)\n",
    "x_u_scaled = u_scaler.transform(x_u)\n",
    "\n",
    "target_scaler = MinMaxScaler()\n",
    "target_scaler.fit(targets.reshape(-1,1))\n",
    "targets_scaled = target_scaler.transform(targets.reshape(-1,1))\n",
    "\n",
    "x_m_scaled.shape, x_u_scaled.shape, targets_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40707, 17), (10177, 17), (40707, 17), (10177, 17), (40707, 1), (10177, 1))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_train, m_test = train_test_split(x_m_scaled, train_size =0.8, shuffle=True, random_state=36)\n",
    "u_train, u_test = train_test_split(x_u_scaled, train_size=0.8, shuffle=True, random_state=36)\n",
    "y_train, y_test = train_test_split(targets_scaled, train_size=0.8, shuffle=True, random_state=36)\n",
    "\n",
    "m_train.shape, m_test.shape, u_train.shape, u_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_19 (InputLayer)       [(None, 14)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_20 (InputLayer)       [(None, 16)]                 0         []                            \n",
      "                                                                                                  \n",
      " sequential_20 (Sequential)  (None, 32)                   40864     ['input_19[0][0]']            \n",
      "                                                                                                  \n",
      " sequential_21 (Sequential)  (None, 32)                   41376     ['input_20[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize_18 (T  (None, 32)                   0         ['sequential_20[0][0]']       \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize_19 (T  (None, 32)                   0         ['sequential_21[0][0]']       \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " dot_9 (Dot)                 (None, 1)                    0         ['tf.math.l2_normalize_18[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'tf.math.l2_normalize_19[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 82240 (321.25 KB)\n",
      "Trainable params: 82240 (321.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "u_NN = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units = 256, activation='relu', name='layer1'),\n",
    "    tf.keras.layers.Dense(units = 128, activation='relu', name='layer2'),\n",
    "    tf.keras.layers.Dense(units = 32, activation='linear', name='layer3'),\n",
    "])\n",
    "\n",
    "m_NN = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units = 256, activation='relu', name='layer1'),\n",
    "    tf.keras.layers.Dense(units = 128, activation='relu', name='layer2'),\n",
    "    tf.keras.layers.Dense(units = 32, activation='linear', name='layer3'),\n",
    "])\n",
    "\n",
    "u_input_layer = tf.keras.layers.Input(shape=xu_num_features)\n",
    "vu = u_NN(u_input_layer)\n",
    "vu = tf.linalg.l2_normalize(vu, axis=1)\n",
    "\n",
    "m_input_layer = tf.keras.layers.Input(shape=xm_num_features)\n",
    "vm = m_NN(m_input_layer)\n",
    "vm = tf.linalg.l2_normalize(vm, axis=1)\n",
    "\n",
    "result = tf.keras.layers.Dot(axes=1)([vu, vm])\n",
    "\n",
    "model = tf.keras.Model([u_input_layer, m_input_layer], result)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_fn = tf.keras.losses.MeanSquaredError()\n",
    "opt = tf.keras.optimizers.Adadelta(learning_rate=0.01)\n",
    "model.compile(optimizer=opt, loss=cost_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1273/1273 [==============================] - 8s 5ms/step - loss: 0.0910\n",
      "Epoch 2/10\n",
      "1273/1273 [==============================] - 5s 4ms/step - loss: 0.0321\n",
      "Epoch 3/10\n",
      "1273/1273 [==============================] - 6s 5ms/step - loss: 0.0301\n",
      "Epoch 4/10\n",
      "1273/1273 [==============================] - 7s 5ms/step - loss: 0.0291\n",
      "Epoch 5/10\n",
      "1273/1273 [==============================] - 6s 4ms/step - loss: 0.0284\n",
      "Epoch 6/10\n",
      "1273/1273 [==============================] - 5s 4ms/step - loss: 0.0279\n",
      "Epoch 7/10\n",
      "1273/1273 [==============================] - 5s 4ms/step - loss: 0.0274\n",
      "Epoch 8/10\n",
      "1273/1273 [==============================] - 6s 4ms/step - loss: 0.0270\n",
      "Epoch 9/10\n",
      "1273/1273 [==============================] - 6s 5ms/step - loss: 0.0267\n",
      "Epoch 10/10\n",
      "1273/1273 [==============================] - 6s 5ms/step - loss: 0.0264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x12e557450>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([u_train[:,xu_start:], m_train[:,xm_start:]], y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1273/1273 [==============================] - 5s 4ms/step - loss: 0.0262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.02618410438299179"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([u_train[:,xu_start:], m_train[:,xm_start:]], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction for a new user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_id = 5000\n",
    "new_rating_ave = 0.0\n",
    "new_action = 0.0\n",
    "new_adventure = 5.0 # preference 1\n",
    "new_animation = 0.0\n",
    "new_childrens = 0.0\n",
    "new_comedy = 0.0\n",
    "new_crime = 0.0\n",
    "new_documentary = 0.0\n",
    "new_drama = 0.0\n",
    "new_fantasy = 5.0 # preference 2\n",
    "new_horror = 0.0\n",
    "new_mystery = 0.0\n",
    "new_romance = 0.0\n",
    "new_scifi = 0.0\n",
    "new_thriller = 0.0\n",
    "new_rating_count = 3\n",
    "\n",
    "user_vec = np.array([[new_user_id, new_rating_count, new_rating_ave,\n",
    "                      new_action, new_adventure, new_animation, new_childrens,\n",
    "                      new_comedy, new_crime, new_documentary,\n",
    "                      new_drama, new_fantasy, new_horror, new_mystery,\n",
    "                      new_romance, new_scifi, new_thriller]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use user vector and predict on a catalogue of items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/27 [>.............................] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "item_vecs = np.genfromtxt('./Lab4_data_catalogue.csv', delimiter=',')\n",
    "\n",
    "x_u_predict = np.tile(user_vec, (len(item_vecs),1))\n",
    "x_u_predict_scaled = u_scaler.transform(x_u_predict)\n",
    "x_m_predict_scaled = u_scaler.transform(item_vecs)\n",
    "\n",
    "prediction_scaled = model.predict([x_u_predict_scaled[:,xu_start:], x_m_predict_scaled[:,xm_start:]])\n",
    "prediction = target_scaler.inverse_transform(prediction_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5618.  ,  2001.  ,     4.16,     0.  ,     1.  ,     1.  ,\n",
       "            0.  ,     0.  ,     0.  ,     0.  ,     0.  ,     1.  ,\n",
       "            0.  ,     0.  ,     0.  ,     0.  ,     0.  ],\n",
       "       [31658.  ,  2004.  ,     4.08,     0.  ,     1.  ,     1.  ,\n",
       "            0.  ,     0.  ,     0.  ,     0.  ,     0.  ,     1.  ,\n",
       "            0.  ,     0.  ,     1.  ,     0.  ,     0.  ],\n",
       "       [ 7153.  ,  2003.  ,     4.12,     1.  ,     1.  ,     0.  ,\n",
       "            0.  ,     0.  ,     0.  ,     0.  ,     1.  ,     1.  ,\n",
       "            0.  ,     0.  ,     0.  ,     0.  ,     0.  ],\n",
       "       [ 4993.  ,  2001.  ,     4.11,     0.  ,     1.  ,     0.  ,\n",
       "            0.  ,     0.  ,     0.  ,     0.  ,     0.  ,     1.  ,\n",
       "            0.  ,     0.  ,     0.  ,     0.  ,     0.  ],\n",
       "       [92535.  ,  2011.  ,     4.3 ,     0.  ,     0.  ,     0.  ,\n",
       "            0.  ,     1.  ,     0.  ,     0.  ,     0.  ,     0.  ,\n",
       "            0.  ,     0.  ,     0.  ,     0.  ,     0.  ]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_index = np.argsort(-prediction, axis=0).reshape(-1).tolist()\n",
    "sorted_prediction = prediction[sorted_index]\n",
    "sorted_items = item_vecs[sorted_index]\n",
    "\n",
    "sorted_items[0:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, selection was done according to user's preferences "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
