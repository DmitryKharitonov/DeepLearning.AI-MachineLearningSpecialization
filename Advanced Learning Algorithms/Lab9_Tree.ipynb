{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Given\n",
    "\n",
    "A sample of categorical data:\n",
    "\n",
    "|   Ear Shape | Face Shape | Whiskers |   Cat (1-yes, 0-no)  |\n",
    "|:---------:|:-----------:|:---------:|:------:|\n",
    "|   Pointy   |   Round     |  Present  |    1   |\n",
    "|   Floppy   |  Not Round  |  Present  |    1   |\n",
    "|   Floppy   |  Round      |  Absent   |    0   |\n",
    "|   Pointy   |  Not Round  |  Present  |    0   |\n",
    "\n",
    "\n",
    "# Find \n",
    "\n",
    "one hot encode the features and build the decision tree:\n",
    "- find the feature to split (entropy)\n",
    "    - define impurity\n",
    "    - calculate information gain\n",
    "- split recursively\n",
    "- stop splitting\n",
    "    - when node is 100% purity\n",
    "    - maximum depth of tree exceeds the defined level\n",
    "    - improvements in information gain is too small\n",
    "    - number of examples in the node is lower than predefined threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 3), (10,))"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1, 1, 1], [0, 0, 1], [0, 1, 0], [1, 0, 1], [1, 1, 1], [1, 1, 0], [0, 0, 0], [1, 1, 0], [0, 1, 0], [0, 1, 0]])\n",
    "y = np.array([1, 1, 0, 0, 1, 1, 0, 1, 0, 0])\n",
    "\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropy \n",
    "\n",
    "* in general for multi-class problems:\n",
    "$$H(X) = -\\sum_{i=1}^{n} p(x_i) \\log_{2}(p(x_i))$$\n",
    "\n",
    "* in binary classification simplifies to:\n",
    "$$H(p_1) = -p_1 \\text{log}_2(p_1) - (1- p_1) \\text{log}_2(1- p_1)$$\n",
    "where $p_1$ is the quantity of dogs (1s) in the dataset, and $p_0 = 1-p_1$ is the probability of cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(branch):\n",
    "    # In - inner branch with values inside = [0, 1, 1, 0, 1]\n",
    "    # Out - \n",
    "    #   entropy = dirtiness of a dataset. 0 - ideal, 1 - bad\n",
    "    #   p - weight\n",
    "\n",
    "    p = np.sum(branch) / len(branch)\n",
    "    \n",
    "    if p==1 or p==0:\n",
    "        entropy = 0\n",
    "    else:\n",
    "        entropy = - p * np.log2(p) - (1-p) * np.log2(1-p)\n",
    "    \n",
    "    return entropy, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information gain\n",
    "\n",
    "* in mgeneral for multi-class:\n",
    "\n",
    "    $$\\text{Information Gain}(S, A) = \\text{Entropy}(S) - \\sum_{v \\in \\text{Values}(A)} \\frac{|S_v|}{|S|} \\cdot \\text{Entropy}(S_v)$$\n",
    "\n",
    "    , where \n",
    "    * $S$ = dataset, \n",
    "    * $A$ = attribute, \n",
    "    * $|S|$ - total number of instances in the dataset $S$,\n",
    "    * $|S_v|$ - subset of instances where attribute $A$ has value $v$\n",
    "    * $\\text{Values}(A)$ - possible values of attribute A \n",
    "    \n",
    "<p>\n",
    "\n",
    "* in binary classiciation simplifies to:\n",
    "\n",
    "$$\\text{Information Gain} = H(p_{root})- \\left(w_{\\text{left}}\\cdot H\\left(p_1^\\text{left}\\right) + w_{\\text{right}}\\cdot H\\left(p_1^\\text{right}\\right)\\right),$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ig(parent, children = []):\n",
    "\n",
    "    H_root, _ = calculate_entropy(parent)\n",
    "\n",
    "    sum = 0\n",
    "\n",
    "    for child in children:\n",
    "\n",
    "        H, w = calculate_entropy(child)\n",
    "        sum += H * w\n",
    "\n",
    "    IG = H_root - sum\n",
    "    \n",
    "    return IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2780719051126377"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_ig(y, [y[x[:,0]==0],y[x[:,0]==1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_feature(x, y, processed_nodes = []):\n",
    "\n",
    "    ig = []\n",
    "\n",
    "    for feature_id in range(x.shape[1]):\n",
    "        if feature_id not in processed_nodes:\n",
    "            left_subset = y[x[:,feature_id]==0]\n",
    "            right_subset = y[x[:,feature_id]==1]\n",
    "            feature_ig = calculate_ig(y, [left_subset, right_subset])\n",
    "            ig.append(feature_ig)\n",
    "        else:\n",
    "            ig.append(0)\n",
    "\n",
    "    print(ig)\n",
    "\n",
    "    return(np.argmax(ig))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_feature(x, feature_to_split_on):\n",
    "    # input - x - dataset\n",
    "    #   feature = 2 (ex)\n",
    "    # output - tbd\n",
    "\n",
    "    feature_idx = {}\n",
    "\n",
    "    for feature in x[:,feature_to_split_on]:\n",
    "        idx = np.where(x[:,feature_to_split_on]==feature)\n",
    "        feature_idx[feature] = idx\n",
    "\n",
    "    return feature_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: (array([0, 3, 4, 5, 7]),), 0: (array([1, 2, 6, 8, 9]),)}"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_feature(x,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree and node classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode():\n",
    "\n",
    "    left_feature_id = -1\n",
    "    right_feature_id = -1\n",
    "\n",
    "    rows_idx = []\n",
    "    path = []\n",
    "\n",
    "    left_feature = TreeNode()\n",
    "    right_feature = TreeNode()\n",
    "\n",
    "    def __repr__(self):\n",
    "        attrs = vars(self)\n",
    "        return ', '.join(f\"{key}={value}\" for key, value in attrs.items())\n",
    "\n",
    "\n",
    "class Tree():\n",
    "    root_feature = -1\n",
    "    node = TreeNode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(current = TreeNode(), x = [[]], y = [], path = []):\n",
    "\n",
    "    if len(path) > 1:\n",
    "        print(\"bottom\")\n",
    "        return 0\n",
    "\n",
    "    # calculate left and right split based on the parent\n",
    "\n",
    "    parent = path[-1]\n",
    "\n",
    "    x_left = x[x[:,parent]==0]\n",
    "    x_right = x[x[:,parent]==1]\n",
    "\n",
    "    y_left = y[x[:,parent]==0]\n",
    "    y_right = y[x[:,parent]==1]\n",
    "\n",
    "    best_split_left = choose_best_feature(x_left, y_left, processed_nodes=path)\n",
    "    best_split_right = choose_best_feature(x_right, y_right, processed_nodes=path)\n",
    "\n",
    "    # call function again for each of the splits\n",
    "\n",
    "    current.left_feature_id = best_split_left\n",
    "    current.right_feature_id = best_split_right\n",
    "    current.path = path\n",
    "    current.rows_idx = \"all\"\n",
    "\n",
    "    print(current)\n",
    "\n",
    "    process(current.left_feature, x_left, y_left, path + [best_split_left])\n",
    "    process(current.left_feature, x_right, y_right, path + [best_split_right])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2780719051126377, 0.13091388234321688, 0.08544279530415388]\n",
      "[0, 0.22192809488736231, 0.7219280948873623]\n",
      "[0, 0.7219280948873623, 0.10973087218436928]\n",
      "left_feature_id=2, right_feature_id=1, path=[0], rows_idx=all\n",
      "bottom\n",
      "bottom\n"
     ]
    }
   ],
   "source": [
    "tree = Tree()\n",
    "tree.root_feature = choose_best_feature(x, y)\n",
    "\n",
    "\n",
    "process(tree.node, x, y, path=[tree.root_feature,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.TreeNode object at 0x110b388d0>\n"
     ]
    }
   ],
   "source": [
    "print(tree.node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_branch(parent):\n",
    "\n",
    "    \"\"\"\n",
    "    parent = [his_x_idx, his_y_idx, processed_features]\n",
    "    child = {feature_id: 2, true: [new_x, new_y, processed_features], false: [new_x, new_y, processed_features]}\n",
    "    \"\"\"\n",
    "\n",
    "    x = parent[0]\n",
    "    y = parent[1]\n",
    "    processed_features = parent[2]\n",
    "\n",
    "    # list features available [1,2,3]\n",
    "        # calculate ig for each feature\n",
    "\n",
    "    ig = []\n",
    "\n",
    "    for feature in range(x.shape[1]):\n",
    "        if feature not in processed_features:\n",
    "            left_branch = y[x[:,feature]==0]\n",
    "            right_branch = y[x[:,feature]==1]\n",
    "            ig.append(calculate_ig(y, left_branch, right_branch))\n",
    "\n",
    "    if np.sum(ig) == 0:\n",
    "        print(\"all features processed\")\n",
    "        return 0\n",
    "\n",
    "    # pick max ig and add to the tree [3]\n",
    "\n",
    "    best_pick = np.argmax(ig)\n",
    "\n",
    "    print(f\"best pick = {best_pick}, ig = {ig}\")\n",
    "\n",
    "    # split the features in left/right [x_left, x_right]\n",
    "\n",
    "    _,  = split_feature(x, best_pick)\n",
    "\n",
    "    fork = [left_idx, right_idx]\n",
    "\n",
    "    # add to the tree [x_left ig][x_right ig]\n",
    "        \n",
    "    return fork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best pick = 0, ig = [0.2780719051126377, 0.13091388234321688, 0.08544279530415388]\n"
     ]
    }
   ],
   "source": [
    "decisionTree = tree()\n",
    "\n",
    "processed_nodes = []\n",
    "\n",
    "best_pick, left_idx, right_idx = build_branch([x, y])\n",
    "processed_nodes.append(best_pick)\n",
    "decisionTree[best_pick]['no']=[left_idx, right_idx]\n",
    "decisionTree[best_pick]['yes']=[left_idx, right_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scan_tree_inside(decisionTree):\n",
    "\n",
    "    for key, value in decisionTree.items():\n",
    "        if type(value) == collections.defaultdict:\n",
    "            scan_tree_inside(value)\n",
    "        else:\n",
    "            print(f\"{key}:{value}\")\n",
    "\n",
    "            best_pick, x_left, x_right, y_left, y_right = build_branch([x, y])\n",
    "            decisionTree[key][best_pick]['no'] = [x_left, y_left]\n",
    "            decisionTree[key][best_pick]['yes'] = [x_right, y_right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no:[(array([1, 2, 6, 8, 9]),), (array([0, 3, 4, 5, 7]),)]\n",
      "best pick = 0, ig = [0.2780719051126377, 0.13091388234321688, 0.08544279530415388]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/dmitriikharitonov/Workspace/DeepLearning.AI-MachineLearningSpecialization/Advanced Learning Algorithms/Lab9_Tree.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dmitriikharitonov/Workspace/DeepLearning.AI-MachineLearningSpecialization/Advanced%20Learning%20Algorithms/Lab9_Tree.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m scan_tree_inside(decisionTree)\n",
      "\u001b[1;32m/Users/dmitriikharitonov/Workspace/DeepLearning.AI-MachineLearningSpecialization/Advanced Learning Algorithms/Lab9_Tree.ipynb Cell 18\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dmitriikharitonov/Workspace/DeepLearning.AI-MachineLearningSpecialization/Advanced%20Learning%20Algorithms/Lab9_Tree.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m decisionTree\u001b[39m.\u001b[39mitems():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dmitriikharitonov/Workspace/DeepLearning.AI-MachineLearningSpecialization/Advanced%20Learning%20Algorithms/Lab9_Tree.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(value) \u001b[39m==\u001b[39m collections\u001b[39m.\u001b[39mdefaultdict:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dmitriikharitonov/Workspace/DeepLearning.AI-MachineLearningSpecialization/Advanced%20Learning%20Algorithms/Lab9_Tree.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         scan_tree_inside(value)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dmitriikharitonov/Workspace/DeepLearning.AI-MachineLearningSpecialization/Advanced%20Learning%20Algorithms/Lab9_Tree.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dmitriikharitonov/Workspace/DeepLearning.AI-MachineLearningSpecialization/Advanced%20Learning%20Algorithms/Lab9_Tree.ipynb#X31sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/Users/dmitriikharitonov/Workspace/DeepLearning.AI-MachineLearningSpecialization/Advanced Learning Algorithms/Lab9_Tree.ipynb Cell 18\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dmitriikharitonov/Workspace/DeepLearning.AI-MachineLearningSpecialization/Advanced%20Learning%20Algorithms/Lab9_Tree.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dmitriikharitonov/Workspace/DeepLearning.AI-MachineLearningSpecialization/Advanced%20Learning%20Algorithms/Lab9_Tree.ipynb#X31sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dmitriikharitonov/Workspace/DeepLearning.AI-MachineLearningSpecialization/Advanced%20Learning%20Algorithms/Lab9_Tree.ipynb#X31sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     best_pick, x_left, x_right, y_left, y_right \u001b[39m=\u001b[39m build_branch([x, y])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dmitriikharitonov/Workspace/DeepLearning.AI-MachineLearningSpecialization/Advanced%20Learning%20Algorithms/Lab9_Tree.ipynb#X31sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     decisionTree[key][best_pick][\u001b[39m'\u001b[39m\u001b[39mno\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [x_left, y_left]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dmitriikharitonov/Workspace/DeepLearning.AI-MachineLearningSpecialization/Advanced%20Learning%20Algorithms/Lab9_Tree.ipynb#X31sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     decisionTree[key][best_pick][\u001b[39m'\u001b[39m\u001b[39myes\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [x_right, y_right]\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 3)"
     ]
    }
   ],
   "source": [
    "scan_tree_inside(decisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.tree()>,\n",
       "            {0: defaultdict(<function __main__.tree()>,\n",
       "                         {'no': [(array([1, 2, 6, 8, 9]),),\n",
       "                           (array([0, 3, 4, 5, 7]),)],\n",
       "                          'yes': [(array([1, 2, 6, 8, 9]),),\n",
       "                           (array([0, 3, 4, 5, 7]),)]})})"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
